{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get story text\n",
    "with open('schoolmistress.txt') as f:\n",
    "  schoolmistress_sentences = f.read().splitlines()\n",
    "\n",
    "schoolmistress_words = []\n",
    "for i in range(len(schoolmistress_sentences)):\n",
    "  for word in schoolmistress_sentences[i].split(\" \"):\n",
    "    word_cleaned = re.sub(r'[\\\",\\(,\\),\\,,\\;,\\.,\\?,\\!,\\:]', '', word)\n",
    "    schoolmistress_words.append({\n",
    "      \"sentence\": i,\n",
    "      \"word\": word_cleaned,\n",
    "      \"word_length\": len(word_cleaned)\n",
    "    })\n",
    "\n",
    "with open('expensivelessons.txt') as f:\n",
    "  el_sentences = f.read().splitlines()\n",
    "\n",
    "el_words = []\n",
    "for i in range(len(el_sentences)):\n",
    "  for word in el_sentences[i].split(\" \"):\n",
    "    word_cleaned = re.sub(r'[\\\",\\(,\\),\\,,\\;,\\.,\\?,\\!,\\:]', '', word)\n",
    "    el_words.append({\n",
    "      \"sentence\": i,\n",
    "      \"word\": word_cleaned,\n",
    "      \"word_length\": len(word_cleaned)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(file_path):\n",
    "  f = open(file_path, 'r')\n",
    "  dict_list = f.readlines()\n",
    "  return list(map(lambda x: json.loads(x), dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get book nlp features\n",
    "schoolmistress_emotion_json = convert_to_json('../emotional_story_arcs/data/kelsey/results/schoolmistress.emotion')\n",
    "schoolmistress_sentiment = pd.read_csv('../emotional_story_arcs/data/kelsey/results/schoolmistress.sentiment', sep='\\t', names=['negative', 'neutral', 'positive'])\n",
    "schoolmistress_emotion = pd.DataFrame.from_dict(schoolmistress_emotion_json)\n",
    "\n",
    "el_emotion_json = convert_to_json('../emotional_story_arcs/data/kelsey/results/expensivelessons.emotion')\n",
    "el_sentiment = pd.read_csv('../emotional_story_arcs/data/kelsey/results/expensivelessons.sentiment', sep='\\t', names=['negative', 'neutral', 'positive'])\n",
    "el_emotion = pd.DataFrame.from_dict(el_emotion_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_logs(filename, sentiment, emotion, words):\n",
    "  # append story text to eyelink file\n",
    "  eyelink_data = pd.read_csv(f'ia_files/{filename}.txt', sep='\\t', low_memory=False)\n",
    "  eyelink_data.head()\n",
    "  words_df = pd.DataFrame(words)\n",
    "  ia_df_subset = eyelink_data[[ 'IA_DWELL_TIME', 'IA_REGRESSION_PATH_DURATION', 'IA_AVERAGE_FIX_PUPIL_SIZE', \n",
    "        'IA_REGRESSION_IN_COUNT','IA_REGRESSION_OUT_FULL_COUNT']] \\\n",
    "        .applymap(lambda x: None if x == '.' else x)\n",
    "  ia_df_clean = pd.DataFrame(ia_df_subset, dtype='float')\n",
    "  eyelink_with_text = pd.concat([words_df, ia_df_clean], axis=1)\n",
    "\n",
    "  # aggregate columns to get sentence vals\n",
    "  ia_sentences_df = eyelink_with_text.groupby('sentence')\\\n",
    "      .agg({'IA_DWELL_TIME': 'sum', 'IA_REGRESSION_PATH_DURATION': 'sum',\n",
    "                    'IA_AVERAGE_FIX_PUPIL_SIZE': 'mean', 'IA_REGRESSION_IN_COUNT': 'sum',\n",
    "                    'IA_REGRESSION_OUT_FULL_COUNT': 'sum'})\n",
    "  # Get highlight categories\n",
    "  highlights = pd.read_csv(f'./highlights/{filename}.csv').drop(['Unnamed: 0', 'proportion'], axis=1)\n",
    "  # BookNLP features + some eye tracking features in one DataFrame by sentence\n",
    "  sentences_with_features = pd.concat([sentiment, emotion], axis=1)\n",
    "  sentences_with_features = pd.concat([sentences_with_features, ia_sentences_df], axis=1)\n",
    "  sentences_with_features = pd.concat([sentences_with_features, highlights], axis=1)\n",
    "  sentences_with_features.to_csv(f\"./results/{filename}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IA_DIR = \"./ia_files/\"\n",
    "\n",
    "for filename in os.listdir(IA_DIR):\n",
    "    f = os.path.join(IA_DIR,filename)\n",
    "    if os.path.isfile(f):\n",
    "        filename = f.replace(IA_DIR, '').replace('.txt', '')\n",
    "        if 'schoolmistress' in filename:\n",
    "          process_logs(filename, schoolmistress_sentiment, schoolmistress_emotion, schoolmistress_words)\n",
    "        elif 'el' in filename:\n",
    "          process_logs(filename, el_sentiment, el_emotion, el_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-scraps-fAaJKGr8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (main, Jan 15 2022, 11:40:53) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "581f1045db2280ff6b67f7603a6643419e6d4ff8b0ea51ff4bcc2bb23747725a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

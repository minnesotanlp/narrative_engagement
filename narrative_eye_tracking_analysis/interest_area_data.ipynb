{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_QUESTIONS = ['lastPageQuestionsRadio0','lastPageQuestionsRadio1','lastPageQuestionsRadio2','lastPageQuestionsRadio3','lastPageQuestionsRadio4','lastPageQuestionsRadio5','lastPageQuestionsRadio6','lastPageQuestionsRadio7','lastPageQuestionsRadio8']\n",
    "SCALE_QUESTION_TEXT = ['I was curious about what would happen next.',\n",
    "      'The story affected me emotionally.',\n",
    "      'While reading my body was in the room, but my mind was inside the world created by the story.',\n",
    "      'At times while reading, I wanted to know what the writer\\'s intentions were.',\n",
    "      'While reading, when a main character succeeded, I felt happy, and when they suffered in some way, I felt sad.',\n",
    "      'The characters were alive in my imagination.',\n",
    "      'I found my mind wandering while reading the story.',\n",
    "      'I could vividly imagine the scenes in the story.',\n",
    "      'At points, I had a hard time making sense of what was going on in the story.']\n",
    "survey_results = pd.read_csv('survey_results.csv')\n",
    "engagement_total = {'el': 0, 'schoolmistress': 0}\n",
    "OUTLIER_COUNT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_engagement_score(id, story):\n",
    "  score = 0\n",
    "  row = survey_results[(survey_results['participant_id'] == id) & (survey_results['story'] == story)]\n",
    "  for i in SCALE_QUESTIONS:\n",
    "    if i == 'lastPageQuestionsRadio6' or i == 'lastPageQuestionsRadio8':\n",
    "      score -= (int(row[i]) - 1) # make scale 0 - 4 so that a 1 for negative quesitons does not affect total\n",
    "    else:\n",
    "      score += (int(row[i]) - 1)\n",
    "  engagement_score = (np.round(score / 7, 2)) # divide by number of positive questions\n",
    "  engagement_total[story] += engagement_score\n",
    "  return engagement_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_concreteness_score(word):\n",
    "  concreteness_dataset = pd.read_csv('../brysbaert_concreteness_scores_2013.csv')\n",
    "  word_indexes = concreteness_dataset.loc[concreteness_dataset['Word'] == word, 'Conc.M']\n",
    "  return \".\" if len(word_indexes) == 0 else word_indexes.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valence_scores(word):\n",
    "  valence_dataset = pd.read_csv('./NRC-VAD-Lexicon.csv', sep='\\t')\n",
    "  word_indexes_valence = valence_dataset.loc[valence_dataset['word'] == word.lower(), 'valence']\n",
    "  word_indexes_arousal = valence_dataset.loc[valence_dataset['word'] == word.lower(), 'arousal']\n",
    "  return (\".\",\".\") if len(word_indexes_valence) == 0 else (word_indexes_valence.iloc[0], word_indexes_arousal.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_freq(word):\n",
    "    freq_df = pd.read_csv('subtlex.csv')\n",
    "    zipf_scores = freq_df.loc[freq_df['Word'] == word.lower(), 'Zipf-value']\n",
    "    return zipf_scores.iloc[0] if len(zipf_scores > 0) else 1.5 ## TODO: get better fallback freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ia_words(story):\n",
    "  with open(f'{story}.txt') as f:\n",
    "    sentences = f.read().splitlines()\n",
    "\n",
    "  words = []\n",
    "  for i in range(len(sentences)):\n",
    "    for word in sentences[i].split(\" \"):\n",
    "      word_cleaned = re.sub(r'[\\\",\\(,\\),\\,,\\;,\\.,\\?,\\!,\\:]', '', word).lower()\n",
    "      words.append({\n",
    "        \"sentence\": i,\n",
    "        \"word\": word_cleaned,\n",
    "        \"word_length\": len(word_cleaned),\n",
    "        \"word_freq\": get_word_freq(word_cleaned),\n",
    "      })\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_sentences(story):\n",
    "  with open(f'{story}.txt') as f:\n",
    "    sentences = f.read().splitlines()\n",
    "\n",
    "  tokens_df = pd.read_csv(f\"../emotional_story_arcs/data/kelsey/results/{story}.tokens\", sep= '\\t', quoting=3)\n",
    "  # filter out punctuation\n",
    "  tokens_df = tokens_df[tokens_df['POS_tag'] != 'PUNCT']\n",
    "  tokens_df['sentence'] = tokens_df['sentence_ID']\n",
    "  tokens_df['word'] = tokens_df['lemma']\n",
    "  tokens_df['word_length'] = tokens_df['lemma'].apply(lambda x: len(x))\n",
    "  tokens_df['concreteness'] = tokens_df['lemma'].apply(lambda x: compute_concreteness_score(x))\n",
    "  tokens_df['valence'] = tokens_df['lemma'].apply(lambda x: compute_valence_scores(x)[0])\n",
    "  tokens_df['arousal'] = tokens_df['lemma'].apply(lambda x: compute_valence_scores(x)[1])\n",
    "  tokens_df['word_freq'] = tokens_df['lemma'].apply(lambda x: get_word_freq(x))\n",
    "\n",
    "  return (sentences, tokens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get story text\n",
    "# schoolmistress_sentences, schoolmistress_words = get_story_sentences('schoolmistress')\n",
    "# el_sentences, el_words = get_story_sentences('expensivelessons')\n",
    "# schoolmistress_ia_words = get_ia_words('schoolmistress')\n",
    "# el_ia_words = get_ia_words('expensivelessons')\n",
    "\n",
    "# el_words.to_csv(\"el_words.csv\")\n",
    "# schoolmistress_words.to_csv(\"schoolmistress_words.csv\")\n",
    "# pd.DataFrame.from_dict(el_sentences).to_csv(\"el_sentences.csv\")\n",
    "# pd.DataFrame.from_dict(schoolmistress_sentences).to_csv(\"schoolmistress_sentences.csv\")\n",
    "# pd.DataFrame.from_dict(el_ia_words).to_csv(\"el_ia_words.csv\")\n",
    "# pd.DataFrame.from_dict(schoolmistress_ia_words).to_csv(\"schoolmistress_ia_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_words = pd.read_csv(\"el_words.csv\")\n",
    "schoolmistress_words = pd.read_csv(\"schoolmistress_words.csv\")\n",
    "el_sentences = pd.read_csv(\"el_sentences.csv\")\n",
    "schoolmistress_sentences = pd.read_csv(\"schoolmistress_sentences.csv\")\n",
    "el_ia_words= pd.read_csv(\"el_ia_words.csv\")\n",
    "schoolmistress_ia_words= pd.read_csv(\"schoolmistress_ia_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolmistress_valence = []\n",
    "schoolmistress_arousal = []\n",
    "for index, row in schoolmistress_words.iterrows():\n",
    "    val_ar = compute_valence_scores(row['word'])\n",
    "    schoolmistress_valence.append(val_ar[0])\n",
    "    schoolmistress_arousal.append(val_ar[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_valence = []\n",
    "el_arousal = []\n",
    "for index, row in el_words.iterrows():\n",
    "    val_ar = compute_valence_scores(row['word'])\n",
    "    el_valence.append(val_ar[0])\n",
    "    el_arousal.append(val_ar[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolmistress_words['valence'] = schoolmistress_valence\n",
    "schoolmistress_words['arousal'] = schoolmistress_arousal\n",
    "el_words['valence'] = el_valence\n",
    "el_words['arousal'] = el_arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(file_path):\n",
    "  f = open(file_path, 'r')\n",
    "  dict_list = f.readlines()\n",
    "  return list(map(lambda x: json.loads(x), dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_dataframe(story, words, sentences):\n",
    "  word_features = pd.DataFrame.from_dict(words)\n",
    "  word_features = word_features[['sentence', 'word_length', 'concreteness', 'valence', 'arousal', 'word_freq']].applymap(lambda x: None if x == '.' else x)\n",
    "  word_features_clean = pd.DataFrame(word_features, dtype='float')\n",
    "  sentence_features = word_features_clean.groupby('sentence').agg(word_length=('word_length', 'mean'), concreteness=('concreteness', 'mean'), valence_avg=('valence', 'mean'), valence_max=('valence', 'max'), valence_min=('valence', 'min'), arousal_avg=('arousal', 'mean'), arousal_max=('arousal', 'max'), arousal_min=('arousal', 'min'), word_freq=('word_freq', 'sum'))\n",
    "  # get book nlp features\n",
    "  emotion_json = convert_to_json(f'../emotional_story_arcs/data/kelsey/results/{story}.emotion')\n",
    "  features_df = pd.concat([pd.DataFrame.from_dict(emotion_json), \n",
    "              pd.read_csv(f'../emotional_story_arcs/data/kelsey/results/{story}.sentiment', sep='\\t', names=['negative', 'neutral', 'positive'])], axis=1)\n",
    "  features_df = pd.concat([features_df, sentence_features], axis=1)\n",
    "  return (pd.concat([features_df, sentences], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_nulls(arr, k, word_counts):\n",
    "    new_arr = np.zeros(arr.size)\n",
    "    for i in range(arr.size):\n",
    "        if arr[i] > 0 and np.isnan(arr[i]) == False:\n",
    "            new_arr[i] = arr[i]\n",
    "        else:\n",
    "            lower = i-k if i>k else 0\n",
    "            upper = i+k if i+k < arr.size else arr.size\n",
    "            new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n",
    "            if(new_arr[i] == 0):\n",
    "                new_arr[i] = np.nanmean(arr)*(word_counts[i]/np.nanmean(word_counts))\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_logs(filename, features, words, OUTLIER_COUNT):\n",
    "  # append story text to eyelink file\n",
    "  eyelink_data = pd.read_csv(f'ia_files/{filename}.txt', sep='\\t', low_memory=False)\n",
    "  eyelink_data2 = eyelink_data\n",
    "  words_df = pd.DataFrame(words)\n",
    "\n",
    "  ia_df_subset = eyelink_data[['IA_DWELL_TIME', 'IA_REGRESSION_PATH_DURATION', 'IA_AVERAGE_FIX_PUPIL_SIZE', \n",
    "        'IA_REGRESSION_IN_COUNT','IA_REGRESSION_OUT_FULL_COUNT']] \\\n",
    "        .applymap(lambda x: None if x == '.' else x)\n",
    "\n",
    "\n",
    "  ia_df_clean = pd.DataFrame(ia_df_subset, dtype='float')\n",
    "  eyelink_with_text = pd.concat([words_df, ia_df_clean], axis=1)\n",
    "#   lower_array, upper_array = get_iqr(eyelink_with_text, 'IA_DWELL_TIME')\n",
    "  Q1 = np.percentile(eyelink_with_text['IA_DWELL_TIME'], 25,\n",
    "                       method = 'midpoint')\n",
    "  Q3 = np.percentile(eyelink_with_text['IA_DWELL_TIME'], 80,\n",
    "                       method = 'midpoint')\n",
    "  IQR = Q3 - Q1\n",
    "    # Upper bound\n",
    "  upper=Q3+1.5*IQR\n",
    "  upper_array=eyelink_with_text[eyelink_with_text['IA_DWELL_TIME'] >= upper].index\n",
    "  total_words=eyelink_with_text.shape[0]  \n",
    "  OUTLIER_COUNT += upper_array.size\n",
    "# Removing the outliers\n",
    "  eyelink_with_text.drop(upper_array,inplace=True)\n",
    "  # aggregate columns to get sentence vals\n",
    "  ia_sentences_df = eyelink_with_text.groupby('sentence')\\\n",
    "      .agg({ 'IA_DWELL_TIME': 'sum', 'IA_REGRESSION_PATH_DURATION': 'sum',\n",
    "                    'IA_AVERAGE_FIX_PUPIL_SIZE': 'mean', 'IA_REGRESSION_IN_COUNT': 'sum',\n",
    "                    'IA_REGRESSION_OUT_FULL_COUNT': 'sum', 'word': 'count'}, dtype='float')\n",
    "\n",
    "  # set null values to the average of the surrounding values\n",
    "  k = 5\n",
    "  dwell_time = resolve_nulls(ia_sentences_df['IA_DWELL_TIME'].to_numpy(dtype='float'), k, ia_sentences_df['word'].to_numpy(dtype='float'))\n",
    "  regression_path_duration = resolve_nulls(ia_sentences_df['IA_REGRESSION_PATH_DURATION'].to_numpy(dtype='float'), k, ia_sentences_df['word'].to_numpy(dtype='float'))\n",
    "  avg_pupil_size = resolve_nulls(ia_sentences_df['IA_AVERAGE_FIX_PUPIL_SIZE'].to_numpy(dtype='float'), k, ia_sentences_df['word'].to_numpy(dtype='float'))\n",
    "  regression_in_count = resolve_nulls(ia_sentences_df['IA_REGRESSION_IN_COUNT'].to_numpy(dtype='float'), k, ia_sentences_df['word'].to_numpy(dtype='float'))\n",
    "  regression_out_count = resolve_nulls(ia_sentences_df['IA_REGRESSION_OUT_FULL_COUNT'].to_numpy(dtype='float'), k, ia_sentences_df['word'].to_numpy(dtype='float'))\n",
    "  ia_resolved_mat = np.array([dwell_time, regression_path_duration, avg_pupil_size, regression_in_count, regression_out_count]).transpose()\n",
    "  eyelink_data_resolved = pd.DataFrame(ia_resolved_mat, columns=['IA_DWELL_TIME_SMOOTHED', 'IA_REGRESSION_PATH_DURATION_SMOOTHED', 'IA_AVERAGE_FIX_PUPIL_SIZE_SMOOTHED', \n",
    "        'IA_REGRESSION_IN_COUNT_SMOOTHED','IA_REGRESSION_OUT_FULL_COUNT_SMOOTHED'])\n",
    "\n",
    "  # Get highlight categories\n",
    "  highlights = pd.read_csv(f'./highlights/{filename}.csv').drop(['Unnamed: 0', 'percent_highlighted'], axis=1)\n",
    "  # Story features + some eye tracking features in one DataFrame by sentence\n",
    "  sentences_with_features = pd.concat([eyelink_data2[['RECORDING_SESSION_LABEL']][0:len(ia_sentences_df)], ia_sentences_df], axis=1)\n",
    "  sentences_with_features['story'] = 'SM' if filename.split('_')[1].split('.')[0] == 'schoolmistress' else 'EL'\n",
    "  sentences_with_features = pd.concat([highlights, sentences_with_features], axis=1)\n",
    "  sentences_with_features = pd.concat([sentences_with_features, features], axis=1)\n",
    "  sentences_with_features = pd.concat([sentences_with_features, eyelink_data_resolved], axis=1)\n",
    "  sentences_with_features['engagement_score'] = [compute_engagement_score(filename.split('_')[0], filename.split('_')[1].replace('.txt', ''))] * len(sentences_with_features)\n",
    "  sentences_with_features.to_csv(f\"./results/{filename}.csv\", )\n",
    "  return (sentences_with_features, OUTLIER_COUNT, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_36716/1670834417.py:9: RuntimeWarning: Mean of empty slice\n",
      "  new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_36716/1670834417.py:9: RuntimeWarning: Mean of empty slice\n",
      "  new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_36716/1670834417.py:9: RuntimeWarning: Mean of empty slice\n",
      "  new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_36716/1670834417.py:9: RuntimeWarning: Mean of empty slice\n",
      "  new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_36716/1670834417.py:9: RuntimeWarning: Mean of empty slice\n",
      "  new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_36716/1670834417.py:9: RuntimeWarning: Mean of empty slice\n",
      "  new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_36716/1670834417.py:9: RuntimeWarning: Mean of empty slice\n",
      "  new_arr[i] = np.nanmean(arr[lower:upper])*(word_counts[i]/np.nanmean(word_counts[lower:upper]))\n"
     ]
    }
   ],
   "source": [
    "IA_DIR = \"./ia_files/\"\n",
    "total_words=0\n",
    "schoolmistress_features = get_features_dataframe('schoolmistress', schoolmistress_words, schoolmistress_sentences)\n",
    "el_features = get_features_dataframe('expensivelessons', el_words, el_sentences)\n",
    "for filename in os.listdir(IA_DIR):\n",
    "  f = os.path.join(IA_DIR,filename)\n",
    "  if os.path.isfile(f):\n",
    "      filename = f.replace(IA_DIR, '').replace('.txt', '')\n",
    "      if 'schoolmistress' in filename:\n",
    "        sm_feat, OUTLIER_COUNT, word_count = process_logs(filename, schoolmistress_features, schoolmistress_ia_words, OUTLIER_COUNT)\n",
    "      elif 'el' in filename:\n",
    "        sm_feat, OUTLIER_COUNT, word_count = process_logs(filename, el_features, el_ia_words, OUTLIER_COUNT)\n",
    "      total_words+=word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expensive Lessons avg score: 4.19, schoolmistress avg score: 3.87\n"
     ]
    }
   ],
   "source": [
    "print(f\"Expensive Lessons avg score: {np.round(engagement_total['el'] / 23, 2)}, schoolmistress avg score: {np.round(engagement_total['schoolmistress'] / 23, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN values\n",
    "result_df = pd.read_csv(\"./results/id11_el.csv\")\n",
    "# fill_vals = {'IA_DWELL_TIME': 0, 'IA_REGRESSION_PATH_DURATION': 0,\n",
    "#         'IA_AVERAGE_FIX_PUPIL_SIZE': result_df['IA_AVERAGE_FIX_PUPIL_SIZE'].mean(),\n",
    "#         'IA_REGRESSION_IN_COUNT': 0, 'IA_REGRESSION_OUT_COUNT': 0}\n",
    "        \n",
    "fill_vals = {'IA_DWELL_TIME': 'empty', 'IA_REGRESSION_PATH_DURATION': 'empty',\n",
    "        'IA_AVERAGE_FIX_PUPIL_SIZE': 'empty',\n",
    "        'IA_REGRESSION_IN_COUNT': 'empty', 'IA_REGRESSION_OUT_FULL_COUNT': 'empty'}\n",
    "result_df = result_df.fillna(value=fill_vals)\n",
    "result_df = result_df[(result_df['IA_DWELL_TIME'] == 'empty') | \\\n",
    "         (result_df['IA_REGRESSION_PATH_DURATION'] == 'empty') | \\\n",
    "          (result_df['IA_AVERAGE_FIX_PUPIL_SIZE'] == 'empty') | \\\n",
    "            (result_df['IA_REGRESSION_IN_COUNT'] == 'empty') | \\\n",
    "            (result_df['IA_REGRESSION_OUT_FULL_COUNT'] == 'empty')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_empties(df):\n",
    "  fill_vals = {'IA_DWELL_TIME': 'empty', 'IA_REGRESSION_PATH_DURATION': 'empty',\n",
    "        'IA_AVERAGE_FIX_PUPIL_SIZE': 'empty',\n",
    "        'IA_REGRESSION_IN_COUNT': 'empty', 'IA_REGRESSION_OUT_FULL_COUNT': 'empty'}\n",
    "  return df.fillna(value=fill_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_report = result_df\n",
    "for filename in os.listdir('./results'):\n",
    "    f = os.path.join('./results',filename)\n",
    "    if os.path.isfile(f) and f != './results/id11_el.csv':\n",
    "      curr_df = populate_empties(pd.read_csv(f))\n",
    "      curr_empties = curr_df[(curr_df['IA_DWELL_TIME'] == 'empty') | \\\n",
    "         (curr_df['IA_REGRESSION_PATH_DURATION'] == 'empty') | \\\n",
    "          (curr_df['IA_AVERAGE_FIX_PUPIL_SIZE'] == 'empty') | \\\n",
    "            (curr_df['IA_REGRESSION_IN_COUNT'] == 'empty') | \\\n",
    "            (curr_df['IA_REGRESSION_OUT_FULL_COUNT'] == 'empty')\n",
    "        ]\n",
    "      empty_report = pd.concat([empty_report, curr_empties], axis=0)\n",
    "\n",
    "empty_report['tally'] = [1]*len(empty_report)\n",
    "empty_report.to_csv(\"empty_rows.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_empty_report = empty_report.groupby('RECORDING_SESSION_LABEL').agg({\"tally\": 'sum'})\n",
    "grouped_empty_report.to_csv(\"grouped_empty_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve null values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('narrative_engagement-1kgk4Qlh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce6e9f89b8ba06df44163b972ee2537d17b2ddac401432716e00090db9961c19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

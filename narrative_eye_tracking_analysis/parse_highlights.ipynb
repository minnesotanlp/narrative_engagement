{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_index(story_lines):\n",
    "  indexes = []\n",
    "  cur_index = 0\n",
    "  for i in range(len(story_lines)):\n",
    "    indexes.append(cur_index)\n",
    "    cur_index += len(story_lines[i])\n",
    "  indexes.append(cur_index)\n",
    "  return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolmistress_story_paragraphs = open('schoolmistress_paragraphs.txt', 'r').readlines()\n",
    "schoolmistress_story_paragraphs_indexes = get_character_index(schoolmistress_story_paragraphs)\n",
    "schoolmistress_story_sentences = open('schoolmistress.txt', 'r').readlines()\n",
    "schoolmistress_story_sentences_indexes = get_character_index(schoolmistress_story_sentences)\n",
    "\n",
    "el_story_paragraphs = open('expensivelessons_paragraphs.txt', 'r').readlines()\n",
    "el_story_paragraphs_indexes = get_character_index(el_story_paragraphs)\n",
    "el_story_sentences = open('expensivelessons.txt', 'r').readlines()\n",
    "el_story_sentences_indexes = get_character_index(el_story_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_indexes(highlight, indexes):\n",
    "  for i in range(len(highlight) - 1):\n",
    "    highlight[i]['start'] = highlight[i]['start'] + indexes[highlight[-1]['paragraph']]\n",
    "    highlight[i]['end'] = highlight[i]['end'] + indexes[highlight[-1]['paragraph']]\n",
    "  return highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_highlights(filename, story_sentences, story_paragraphs, story_sentences_indexes, story_paragraphs_indexes):\n",
    "  highlight_file = open(f'./highlighting_logs/{filename}.log', 'r')\n",
    "  CATEGORY_MAP = {'None': 0, 'Present': 1, 'Confused': 2, 'Curious': 3, 'Connected': 4, 'Other': 5}\n",
    "  lines = highlight_file.readlines()\n",
    "  highlights = [None] * len(story_paragraphs)\n",
    "  survey_results = []\n",
    "  for line in lines:\n",
    "    start = line.find('Highlight:')\n",
    "    if start != -1:\n",
    "      highlight = json.loads(str(line[start + len('Highlight: '):].replace(\"'\", '\"')), )\n",
    "      highlight_absolute_indexes = update_indexes(highlight, story_paragraphs_indexes)\n",
    "      highlights[highlight[-1]['paragraph']] = highlight_absolute_indexes\n",
    "    survey = re.search(\"Survey\\d:\\s\", line)\n",
    "    if survey != None:\n",
    "      answers_str = \"\"\"{0}\"\"\"\n",
    "      answers_str = answers_str.format(str(line[survey.end():]))\n",
    "\n",
    "      # oh lord.\n",
    "      # print(re.sub(\"'}\", '\"}', re.sub(\"{'\", '{\"', re.sub(\"', \", '\", ', re.sub(r\"(\\: |\\, )'\", r'\\1\"', re.sub(\"(\\d)'\", r'\\1\"', re.sub('\\\\\\\\', \"\", re.sub('\"', \"'\", answers_str))))))))\n",
    "      survey_dict = json.loads(re.sub(\"'}\", '\"}', re.sub(\"{'\", '{\"', re.sub(\"', \", '\", ', re.sub(r\"(\\: |\\, )'\", r'\\1\"', re.sub(\"(\\d)'\", r'\\1\"', re.sub('\\\\\\\\', \"\", re.sub('\"', \"'\", answers_str))))))), )\n",
    "      survey_dict['participant_id'] = filename.split('_')[0].lower()\n",
    "      survey_dict['story'] = filename.split('_')[1].replace('.log', '')\n",
    "      survey_results.append(survey_dict)\n",
    "  sentence_highlights = [{'category': 0, 'proportion': 0.0, 'percent_highlighted': 0.0}] * len(story_sentences)\n",
    "  for i in range(len(highlights)):\n",
    "    if highlights[i] != None:\n",
    "      for k in range(len(highlights[i]) - 1):\n",
    "        start_sent = None\n",
    "        end_sent = None\n",
    "        for p in range(len(story_sentences_indexes) - 1):\n",
    "          if highlights[i][k]['start'] >= story_sentences_indexes[p] and highlights[i][k]['start'] < story_sentences_indexes[p+1]:\n",
    "            start_sent = p\n",
    "          if highlights[i][k]['end'] >= story_sentences_indexes[p] and highlights[i][k]['end'] < story_sentences_indexes[p+1]:\n",
    "            end_sent = p\n",
    "          if start_sent != None:\n",
    "            end_index = story_sentences_indexes[p+1] if end_sent == None else highlights[i][k]['end']\n",
    "            start_index = story_sentences_indexes[p] if story_sentences_indexes[p] > highlights[i][k]['start'] else highlights[i][k]['start']\n",
    "            proportion = (end_index - start_index) / (story_sentences_indexes[p+1] - story_sentences_indexes[p])\n",
    "            if proportion > sentence_highlights[p]['proportion']:\n",
    "              sentence_highlights[p] = {'category': CATEGORY_MAP[highlights[i][k]['tag']], 'proportion': proportion, 'percent_highlighted': sentence_highlights[p]['percent_highlighted'] + proportion}\n",
    "            else:\n",
    "              sentence_highlights[p]['percent_highlighted'] = sentence_highlights[p]['percent_highlighted'] + proportion\n",
    "          if end_sent != None:\n",
    "            break\n",
    "  for sentence in sentence_highlights:\n",
    "    if sentence['proportion'] == 0.0:\n",
    "      sentence['proportion'] = 1.0\n",
    "  highlight_df = pd.DataFrame.from_dict(sentence_highlights)\n",
    "  highlight_df.to_csv(f'./highlights/{filename}.csv')\n",
    "  first_survey = pd.DataFrame.from_dict([survey_results[0]])\n",
    "  last_survey = pd.DataFrame.from_dict([survey_results[1]])\n",
    "  survey_df = pd.concat([first_survey, last_survey], axis=1)\n",
    "  return survey_df.loc[:,~survey_df.columns.duplicated()].copy()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGHLIGHT_DIR = \"./highlighting_logs/\"\n",
    "survey_df = pd.DataFrame()\n",
    "for filename in os.listdir(HIGHLIGHT_DIR):\n",
    "    f = os.path.join(HIGHLIGHT_DIR,filename)\n",
    "    if os.path.isfile(f):\n",
    "        filename = f.replace(HIGHLIGHT_DIR, '').replace('.log', '')\n",
    "        if 'schoolmistress' in filename:\n",
    "          survey = parse_highlights(filename, schoolmistress_story_sentences, schoolmistress_story_paragraphs, schoolmistress_story_sentences_indexes, schoolmistress_story_paragraphs_indexes)\n",
    "        elif 'el' in filename:\n",
    "          survey = parse_highlights(filename, el_story_sentences, el_story_paragraphs, el_story_sentences_indexes, el_story_paragraphs_indexes)\n",
    "        if len(survey_df) == 0:\n",
    "          survey_df = survey\n",
    "        else:\n",
    "          survey_df = pd.concat([survey_df, survey], ignore_index=True)\n",
    "survey_df.to_csv('./survey_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ids(x):\n",
    "    return str(x).lower() if \"id\" in str(x).lower() else \"id\" + str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_percent=pd.read_csv(\"./results/id10_el.csv\", usecols=['RECORDING_SESSION_LABEL', 'Unnamed: 0.1', 'percent_highlighted', 'valence_avg', 'valence_max', 'valence_min', 'arousal_avg', 'arousal_max', 'arousal_min'])\n",
    "highlight_percent['story'] = ['EL']*len(highlight_percent)\n",
    "highlight_percent['RECORDING_SESSION_LABEL'] = highlight_percent['RECORDING_SESSION_LABEL'].apply(normalize_ids)\n",
    "for filename in os.listdir('./results/'):\n",
    "    f = os.path.join('./results/',filename)\n",
    "    if os.path.isfile(f) and f != \"./results/id10_el.csv\":\n",
    "        df = pd.read_csv(f, usecols=['RECORDING_SESSION_LABEL', 'Unnamed: 0.1', 'percent_highlighted', 'valence_avg', 'valence_max', 'valence_min', 'arousal_avg', 'arousal_max', 'arousal_min'])\n",
    "        if \"schoolmistress\" in f:\n",
    "            df['story'] = ['SM']*len(df)\n",
    "        else:\n",
    "            df['story'] = ['EL']*len(df)\n",
    "        highlight_percent['RECORDING_SESSION_LABEL'] = highlight_percent['RECORDING_SESSION_LABEL'].apply(normalize_ids)\n",
    "        highlight_percent = pd.concat([highlight_percent, df])\n",
    "\n",
    "\n",
    "highlight_percent = highlight_percent.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"results_combined.csv\")\n",
    "combined_df['RECORDING_SESSION_LABEL'] = combined_df['RECORDING_SESSION_LABEL'].apply(normalize_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(combined_df, highlight_percent, how='inner', left_on=['RECORDING_SESSION_LABEL', 'story', 'Unnamed..0.1'], right_on=['RECORDING_SESSION_LABEL', 'story', 'Unnamed: 0.1'], copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"combined_with_percent_highlighted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fleiss_kappa(M):\n",
    "    ## Code from: https://towardsdatascience.com/inter-annotator-agreement-2f46c6d37bf3\n",
    "    \"\"\"Computes Fleiss' kappa for group of annotators.\n",
    "    :param M: a matrix of shape (:attr:'N', :attr:'k') with 'N' = number of subjects and 'k' = the number of categories.\n",
    "        'M[i, j]' represent the number of raters who assigned the 'i'th subject to the 'j'th category.\n",
    "    :type: numpy matrix\n",
    "    :rtype: float\n",
    "    :return: Fleiss' kappa score\n",
    "    \"\"\"\n",
    "    N, k = M.shape  # N is # of items, k is # of categories\n",
    "    n_annotators = float(np.sum(M[0, :]))  # # of annotators\n",
    "    tot_annotations = N * n_annotators  # the total # of annotations\n",
    "    category_sum = np.sum(M, axis=0)  # the sum of each category over all items\n",
    "\n",
    "    # chance agreement\n",
    "    p = category_sum / tot_annotations  # the distribution of each category over all annotations\n",
    "    PbarE = np.sum(p * p)  # average chance agreement over all categories\n",
    "\n",
    "    # observed agreement\n",
    "    P = (np.sum(M * M, axis=1) - n_annotators) / (n_annotators * (n_annotators - 1))\n",
    "    Pbar = np.sum(P) / N  # add all observed agreement chances per item and divide by amount of items\n",
    "\n",
    "    return round((Pbar - PbarE) / (1 - PbarE), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare highlights for inter annotator score computation\n",
    "combined_sm = combined_df[combined_df['story'] == 'SM']\n",
    "combined_el = combined_df[combined_df['story'] == 'EL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_26095/3248322664.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_sm['category'] = combined_sm['category'].astype('category')\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_26095/3248322664.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_el['category'] = combined_el['category'].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_sm['category'] = combined_sm['category'].astype('category')\n",
    "highlights_sm = combined_sm.groupby(by=['X', 'category']).agg({'category': 'count'})\n",
    "highlights_sm.shape[0]\n",
    "\n",
    "combined_el['category'] = combined_el['category'].astype('category')\n",
    "highlights_el = combined_el.groupby(by=['X', 'category']).agg({'category': 'count'})\n",
    "highlights_el.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CAT = 6\n",
    "annotator_mat = np.zeros((len(schoolmistress_story_sentences), NUM_CAT), dtype=np.int32)\n",
    "count=0\n",
    "for sent in range(len(schoolmistress_story_sentences)):\n",
    "    for cat in range(NUM_CAT):\n",
    "        count = 0 if len(highlights_sm[(sent*NUM_CAT)+cat:(sent*NUM_CAT)+cat+1]['category'].to_numpy()) == 0 else highlights_sm[(sent*NUM_CAT)+cat:(sent*NUM_CAT)+cat+1]['category'].to_numpy()[0]\n",
    "        annotator_mat[sent][cat] = count \n",
    "\n",
    "annotator_mat_el = np.zeros((len(el_story_sentences), NUM_CAT), dtype=np.int32)\n",
    "count=0\n",
    "for sent in range(len(el_story_sentences)):\n",
    "    for cat in range(NUM_CAT):\n",
    "        count = 0 if len(highlights_el[(sent*NUM_CAT)+cat:(sent*NUM_CAT)+cat+1]['category'].to_numpy()) == 0 else highlights_el[(sent*NUM_CAT)+cat:(sent*NUM_CAT)+cat+1]['category'].to_numpy()[0]\n",
    "        annotator_mat_el[sent][cat] = count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1289"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inter annotator agreement if each highlight category, including none is a separate category\n",
    "fleiss_kappa_score = fleiss_kappa(annotator_mat)\n",
    "fleiss_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0662"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleiss_kappa_score_el = fleiss_kappa(annotator_mat_el)\n",
    "fleiss_kappa_score_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_26095/2984281183.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_sm['binary_label'] = combined_sm['category'].map(lambda x: 0 if x == 0 else 1)\n",
      "/var/folders/h_/r_vs5xw54bj83yf5_5wj_8j40000gq/T/ipykernel_26095/2984281183.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_el['binary_label'] = combined_el['category'].map(lambda x: 0 if x == 0 else 1)\n"
     ]
    }
   ],
   "source": [
    "# Inter annotator agreement if we consider only two categories: highlighted or not highlighted\n",
    "combined_sm['binary_label'] = combined_sm['category'].map(lambda x: 0 if x == 0 else 1)\n",
    "binary_highlights_sm = combined_sm.groupby(by=['X', 'binary_label']).agg({'binary_label': 'count'})\n",
    "\n",
    "combined_el['binary_label'] = combined_el['category'].map(lambda x: 0 if x == 0 else 1)\n",
    "binary_highlights_el = combined_el.groupby(by=['X', 'binary_label']).agg({'binary_label': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binary_annotator_mat = np.zeros((len(schoolmistress_story_sentences), 2), dtype=np.int32)\n",
    "count=0\n",
    "for sent in range(len(schoolmistress_story_sentences)):\n",
    "    for cat in range(2):\n",
    "        count = 0 if len(binary_highlights_sm[(sent*2)+cat:(sent*2)+cat+1]['binary_label'].to_numpy()) == 0 else binary_highlights_sm[(sent*2)+cat:(sent*2)+cat+1]['binary_label'].to_numpy()[0]\n",
    "        binary_annotator_mat[sent][cat] = count \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binary_annotator_mat_el = np.zeros((len(el_story_sentences), 2), dtype=np.int32)\n",
    "count=0\n",
    "for sent in range(len(el_story_sentences)):\n",
    "    for cat in range(2):\n",
    "        count = 0 if len(binary_highlights_el[(sent*2)+cat:(sent*2)+cat+1]['binary_label'].to_numpy()) == 0 else binary_highlights_el[(sent*2)+cat:(sent*2)+cat+1]['binary_label'].to_numpy()[0]\n",
    "        binary_annotator_mat_el[sent][cat] = count \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1529"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_fleiss = fleiss_kappa(binary_annotator_mat)\n",
    "binary_fleiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1098"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_fleiss_el = fleiss_kappa(binary_annotator_mat_el)\n",
    "binary_fleiss_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove none category to see agreement when highlighted\n",
    "no_none_annotator_mat = np.delete(annotator_mat, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_none_annotator_mat_el = np.delete(annotator_mat_el, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_none_fleiss = fleiss_kappa(no_none_annotator_mat)\n",
    "no_none_fleiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0622"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_none_fleiss_el = fleiss_kappa(no_none_annotator_mat_el)\n",
    "no_none_fleiss_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narrative_engagement-1kgk4Qlh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce6e9f89b8ba06df44163b972ee2537d17b2ddac401432716e00090db9961c19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
